
name: 3 - Continuous Staging & Model Promotion

permissions: write-all

on:
  workflow_run:
    workflows: ["2 - Continuous Delivery"]
    types: [completed]
  workflow_dispatch:

env:
  REGISTRY: ${{ vars.REGISTRY }}
  MLFLOW_TRACKING_URI: ${{ vars.MLFLOW_TRACKING_URI }}
  MLFLOW_MODEL_NAME: ${{ vars.MLFLOW_MODEL_NAME }}

jobs:
  stage-tests:
    # Run only if previous stage finished successfully
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.13' }
      - run: pip install uv

      # Log in to GitHub Container Registry
      - uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - run: docker pull ${{ env.REGISTRY }}/${{ github.repository }}/inference-api:staging

      - name: Start inference service with staging model
        env:
          MLFLOW_TRACKING_URI: ${{ env.MLFLOW_TRACKING_URI }}
          MLFLOW_TRACKING_USERNAME: ${{ secrets.MLFLOW_USERNAME }}
          MLFLOW_TRACKING_PASSWORD: ${{ secrets.MLFLOW_PASSWORD }}
          MODEL_ALIAS: staging
          MLFLOW_MODEL_NAME: ${{ env.MLFLOW_MODEL_NAME }}
        run: |
          docker run -d \
            --name inference-api \
            -p 9001:9001 \
            -e MLFLOW_TRACKING_URI \
            -e MLFLOW_TRACKING_USERNAME \
            -e MLFLOW_TRACKING_PASSWORD \
            -e MLFLOW_MODEL_ALIAS=$MODEL_ALIAS \
            -e MLFLOW_MODEL_NAME \
            ${{ env.REGISTRY }}/${{ github.repository }}/inference-api:staging
          
          # Wait for service to be ready
          sleep 10

      - name: Run E2E tests
        run: uv run pytest tests/test_e2e/ -v

      - name: Promote model to production
        if: success()
        env:
          MLFLOW_TRACKING_URI: ${{ env.MLFLOW_TRACKING_URI }}
          MLFLOW_TRACKING_USERNAME: ${{ secrets.MLFLOW_USERNAME }}
          MLFLOW_TRACKING_PASSWORD: ${{ secrets.MLFLOW_PASSWORD }}
          FROM_ALIAS: staging
          TO_ALIAS: production
        run: uv run python model-promotion/promote_model.py

      - name: Push production container tag
        if: success()
        run: |
          docker tag ${{ env.REGISTRY }}/${{ github.repository }}/inference-api:staging \
                     ${{ env.REGISTRY }}/${{ github.repository }}/inference-api:production
          docker push ${{ env.REGISTRY }}/${{ github.repository }}/inference-api:production

      - name: Stop inference service
        if: always()
        run: |
          docker stop inference-api || true
          docker rm inference-api || true

  deploy-to-production:
    needs: stage-tests
    if: success()
    runs-on: inference

    steps:
      - uses: actions/checkout@v4

      - uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Deploy production container
        env:
          REGISTRY: ${{ env.REGISTRY }}
          MODEL_ALIAS: production
        run: |
          docker pull ${{ env.REGISTRY }}/${{ github.repository }}/inference-api:production
          docker compose -f inference.compose.v1.yml pull
          docker compose -f inference.compose.v1.yml down --remove-orphans || true
          docker compose -f inference.compose.v1.yml up -d

      - name: Health check
        run: |
          for i in {1..30}; do
            if curl -f http://localhost:9001/health | grep -q "healthy"; then
              echo "Production service healthy"
              exit 0
            fi
            sleep 2
          done
          exit 1
