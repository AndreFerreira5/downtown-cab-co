services:
  inference_api:
    image: ghcr.io/andreferreira5/downtown-cab-co-inference-api:${IMAGE_TAG:-production}
    container_name: inference-api
    restart: always
    environment:
      - MLFLOW_MODEL_NAME=${MLFLOW_MODEL_NAME}
      - MLFLOW_MODEL_ALIAS=${MLFLOW_MODEL_ALIAS}
      - MLFLOW_TRACKING_URI=${MLFLOW_TRACKING_URI}
    ports:
      - "9001:9001"
